{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import requests\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\sindhuja\\\\Desktop\\\\Spring19\\\\bIGdAT_aSSIGNM'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'Assignment1.ipynb',\n",
       " 'Copy_of_Predict_Shakespeare_with_Cloud_TPUs_and_Keras.ipynb',\n",
       " 'copy_of_predict_shakespeare_with_cloud_tpus_and_keras.py',\n",
       " 'Predict_Shakespeare_with_Cloud_TPUs_and_Keras.html',\n",
       " 'Predict_Shakespeare_with_Cloud_TPUs_and_Keras.ipynb',\n",
       " 'Untitled.ipynb']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\sindhuja\\\\Desktop\\\\Spring19\\\\bIGdAT_aSSIGNM\\\\Predict_Shakespeare_with_Cloud_TPUs_and_Keras.html'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = glob2.glob(\"*TPUs_and_Keras.html\")\n",
    "document1 = current_dir+'\\\\'+(file[0])\n",
    "document1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body>\n",
       "<div class=\"border-box-sizing\" id=\"notebook\" tabindex=\"-1\">\n",
       "<div class=\"container\" id=\"notebook-container\">\n",
       "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
       "</div><div class=\"inner_cell\">\n",
       "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
       "<h5 id=\"Copyright-2018-The-TensorFlow-Hub-Authors.\">Copyright 2018 The TensorFlow Hub Authors.<a class=\"anchor-link\" href=\"#Copyright-2018-The-TensorFlow-Hub-Authors.\">¶</a></h5><p>Licensed under the Apache License, Version 2.0 (the \"License\");</p>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cell border-box-sizing code_cell rendered\">\n",
       "<div class=\"input\">\n",
       "<div class=\"prompt input_prompt\">In [0]:</div>\n",
       "<div class=\"inner_cell\">\n",
       "<div class=\"input_area\">\n",
       "<div class=\" highlight hl-ipython3\"><pre><span></span><span class=\"c1\"># Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.</span>\n",
       "<span class=\"c1\">#</span>\n",
       "<span class=\"c1\"># Licensed under the Apache License, Version 2.0 (the \"License\");</span>\n",
       "<span class=\"c1\"># you may not use this file except in compliance with the License.</span>\n",
       "<span class=\"c1\"># You may obtain a copy of the License at</span>\n",
       "<span class=\"c1\">#</span>\n",
       "<span class=\"c1\">#     http://www.apache.org/licenses/LICENSE-2.0</span>\n",
       "<span class=\"c1\">#</span>\n",
       "<span class=\"c1\"># Unless required by applicable law or agreed to in writing, software</span>\n",
       "<span class=\"c1\"># distributed under the License is distributed on an \"AS IS\" BASIS,</span>\n",
       "<span class=\"c1\"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>\n",
       "<span class=\"c1\"># See the License for the specific language governing permissions and</span>\n",
       "<span class=\"c1\"># limitations under the License.</span>\n",
       "<span class=\"c1\"># ==============================================================================</span>\n",
       "</pre></div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cell border-box-sizing code_cell rendered\">\n",
       "<div class=\"input\">\n",
       "<div class=\"prompt input_prompt\">In [0]:</div>\n",
       "<div class=\"inner_cell\">\n",
       "<div class=\"input_area\">\n",
       "<div class=\" highlight hl-ipython3\"><pre><span></span> \n",
       "</pre></div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
       "</div><div class=\"inner_cell\">\n",
       "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
       "<h2 id=\"Predict-Shakespeare-with-Cloud-TPUs-and-Keras\">Predict Shakespeare with Cloud TPUs and Keras<a class=\"anchor-link\" href=\"#Predict-Shakespeare-with-Cloud-TPUs-and-Keras\">¶</a></h2>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
       "</div><div class=\"inner_cell\">\n",
       "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
       "<h2 id=\"Overview\">Overview<a class=\"anchor-link\" href=\"#Overview\">¶</a></h2><p>This example uses <a href=\"https://www.tensorflow.org/guide/keras\">tf.keras</a> to build a <em>language model</em> and train it on a Cloud TPU. This language model predicts the next character of text given the text so far. The trained model can generate new snippets of text that read in a similar style to the text training data.</p>\n",
       "<p>The model trains for 10 epochs and completes in approximately 5 minutes.</p>\n",
       "<p>This notebook is hosted on GitHub. To view it in its original repository, after opening the notebook, select <strong>File &gt; View on GitHub</strong>.</p>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
       "</div><div class=\"inner_cell\">\n",
       "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
       "<h2 id=\"Learning-objectives\">Learning objectives<a class=\"anchor-link\" href=\"#Learning-objectives\">¶</a></h2><p>In this Colab, you will learn how to:</p>\n",
       "<ul>\n",
       "<li>Build a two-layer, forward-LSTM model.</li>\n",
       "<li>Convert a <code>tf.keras</code> model to an equivalent TPU version and then use the standard Keras methods to train: <code>fit</code>, <code>predict</code>, and <code>evaluate</code>.</li>\n",
       "<li>Use the trained model to make predictions and generate your own Shakespeare-esque play.</li>\n",
       "</ul>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
       "</div><div class=\"inner_cell\">\n",
       "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
       "<h2 id=\"Instructions\">Instructions<a class=\"anchor-link\" href=\"#Instructions\">¶</a></h2>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
       "</div><div class=\"inner_cell\">\n",
       "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
       "<h3>    Train on TPU   <a href=\"https://cloud.google.com/tpu/\"><img src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" valign=\"middle\" width=\"50\"/></a></h3><ol>\n",
       "<li>On the main menu, click Runtime and select <strong>Change runtime type</strong>. Set \"TPU\" as the hardware accelerator.</li>\n",
       "<li>Click Runtime again and select <strong>Runtime &gt; Run All</strong>. You can also run the cells manually with Shift-ENTER. </li>\n",
       "</ol>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
       "</div><div class=\"inner_cell\">\n",
       "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
       "<p>TPUs are located in Google Cloud, for optimal performance, they read data directly from Google Cloud Storage (GCS)</p>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
       "</div><div class=\"inner_cell\">\n",
       "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
       "<h2 id=\"Data,-model,-and-training\">Data, model, and training<a class=\"anchor-link\" href=\"#Data,-model,-and-training\">¶</a></h2>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
       "</div><div class=\"inner_cell\">\n",
       "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
       "<p>In this example, you train the model on the combined works of William Shakespeare, then use the model to compose a play in the style of <em>The Great Bard</em>:</p>\n",
       "<blockquote>\n",
       "Loves that led me no dumbs lack her Berjoy's face with her to-day.  \n",
       "The spirits roar'd; which shames which within his powers  \n",
       "    Which tied up remedies lending with occasion,  \n",
       "A loud and Lancaster, stabb'd in me  \n",
       "    Upon my sword for ever: 'Agripo'er, his days let me free.  \n",
       "    Stop it of that word, be so: at Lear,  \n",
       "    When I did profess the hour-stranger for my life,  \n",
       "    When I did sink to be cried how for aught;  \n",
       "    Some beds which seeks chaste senses prove burning;  \n",
       "But he perforces seen in her eyes so fast;  \n",
       "And _  \n",
       "</blockquote>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
       "</div><div class=\"inner_cell\">\n",
       "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
       "<h3 id=\"Download-data\">Download data<a class=\"anchor-link\" href=\"#Download-data\">¶</a></h3><p>Download <em>The Complete Works of William Shakespeare</em> as a single text file from <a href=\"https://www.gutenberg.org/\">Project Gutenberg</a>. You use snippets from this file as the <em>training data</em> for the model. The <em>target</em> snippet is offset by one character.</p>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cell border-box-sizing code_cell rendered\">\n",
       "<div class=\"input\">\n",
       "<div class=\"prompt input_prompt\">In [0]:</div>\n",
       "<div class=\"inner_cell\">\n",
       "<div class=\"input_area\">\n",
       "<div class=\" highlight hl-ipython3\"><pre><span></span><span class=\"o\">!</span>wget --show-progress --continue -O /content/shakespeare.txt http://www.gutenberg.org/files/100/100-0.txt\n",
       "</pre></div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
       "</div><div class=\"inner_cell\">\n",
       "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
       "<h3 id=\"Build-the-data-generator\">Build the data generator<a class=\"anchor-link\" href=\"#Build-the-data-generator\">¶</a></h3>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cell border-box-sizing code_cell rendered\">\n",
       "<div class=\"input\">\n",
       "<div class=\"prompt input_prompt\">In [0]:</div>\n",
       "<div class=\"inner_cell\">\n",
       "<div class=\"input_area\">\n",
       "<div class=\" highlight hl-ipython3\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">numpy</span> <span class=\"k\">as</span> <span class=\"nn\">np</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">six</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">tensorflow</span> <span class=\"k\">as</span> <span class=\"nn\">tf</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">time</span>\n",
       "<span class=\"kn\">import</span> <span class=\"nn\">os</span>\n",
       "\n",
       "<span class=\"c1\"># This address identifies the TPU we'll use when configuring TensorFlow.</span>\n",
       "<span class=\"n\">TPU_WORKER</span> <span class=\"o\">=</span> <span class=\"s1\">'grpc://'</span> <span class=\"o\">+</span> <span class=\"n\">os</span><span class=\"o\">.</span><span class=\"n\">environ</span><span class=\"p\">[</span><span class=\"s1\">'COLAB_TPU_ADDR'</span><span class=\"p\">]</span>\n",
       "\n",
       "<span class=\"n\">SHAKESPEARE_TXT</span> <span class=\"o\">=</span> <span class=\"s1\">'/content/shakespeare.txt'</span>\n",
       "\n",
       "<span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">set_verbosity</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">INFO</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">transform</span><span class=\"p\">(</span><span class=\"n\">txt</span><span class=\"p\">,</span> <span class=\"n\">pad_to</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n",
       "  <span class=\"c1\"># drop any non-ascii characters</span>\n",
       "  <span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">asarray</span><span class=\"p\">([</span><span class=\"nb\">ord</span><span class=\"p\">(</span><span class=\"n\">c</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">c</span> <span class=\"ow\">in</span> <span class=\"n\">txt</span> <span class=\"k\">if</span> <span class=\"nb\">ord</span><span class=\"p\">(</span><span class=\"n\">c</span><span class=\"p\">)</span> <span class=\"o\">&lt;</span> <span class=\"mi\">255</span><span class=\"p\">],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">int32</span><span class=\"p\">)</span>\n",
       "  <span class=\"k\">if</span> <span class=\"n\">pad_to</span> <span class=\"ow\">is</span> <span class=\"ow\">not</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n",
       "    <span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">output</span><span class=\"p\">[:</span><span class=\"n\">pad_to</span><span class=\"p\">]</span>\n",
       "    <span class=\"n\">output</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">concatenate</span><span class=\"p\">([</span>\n",
       "        <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">zeros</span><span class=\"p\">([</span><span class=\"n\">pad_to</span> <span class=\"o\">-</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">txt</span><span class=\"p\">)],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">int32</span><span class=\"p\">),</span>\n",
       "        <span class=\"n\">output</span><span class=\"p\">,</span>\n",
       "    <span class=\"p\">])</span>\n",
       "  <span class=\"k\">return</span> <span class=\"n\">output</span>\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">training_generator</span><span class=\"p\">(</span><span class=\"n\">seq_len</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">1024</span><span class=\"p\">):</span>\n",
       "  <span class=\"sd\">\"\"\"A generator yields (source, target) arrays for training.\"\"\"</span>\n",
       "  <span class=\"k\">with</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">gfile</span><span class=\"o\">.</span><span class=\"n\">GFile</span><span class=\"p\">(</span><span class=\"n\">SHAKESPEARE_TXT</span><span class=\"p\">,</span> <span class=\"s1\">'r'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">f</span><span class=\"p\">:</span>\n",
       "    <span class=\"n\">txt</span> <span class=\"o\">=</span> <span class=\"n\">f</span><span class=\"o\">.</span><span class=\"n\">read</span><span class=\"p\">()</span>\n",
       "\n",
       "  <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">info</span><span class=\"p\">(</span><span class=\"s1\">'Input text [</span><span class=\"si\">%d</span><span class=\"s1\">] </span><span class=\"si\">%s</span><span class=\"s1\">'</span><span class=\"p\">,</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">txt</span><span class=\"p\">),</span> <span class=\"n\">txt</span><span class=\"p\">[:</span><span class=\"mi\">50</span><span class=\"p\">])</span>\n",
       "  <span class=\"n\">source</span> <span class=\"o\">=</span> <span class=\"n\">transform</span><span class=\"p\">(</span><span class=\"n\">txt</span><span class=\"p\">)</span>\n",
       "  <span class=\"k\">while</span> <span class=\"kc\">True</span><span class=\"p\">:</span>\n",
       "    <span class=\"n\">offsets</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">randint</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">source</span><span class=\"p\">)</span> <span class=\"o\">-</span> <span class=\"n\">seq_len</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"c1\"># Our model uses sparse crossentropy loss, but Keras requires labels</span>\n",
       "    <span class=\"c1\"># to have the same rank as the input logits.  We add an empty final</span>\n",
       "    <span class=\"c1\"># dimension to account for this.</span>\n",
       "    <span class=\"k\">yield</span> <span class=\"p\">(</span>\n",
       "        <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">stack</span><span class=\"p\">([</span><span class=\"n\">source</span><span class=\"p\">[</span><span class=\"n\">idx</span><span class=\"p\">:</span><span class=\"n\">idx</span> <span class=\"o\">+</span> <span class=\"n\">seq_len</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">idx</span> <span class=\"ow\">in</span> <span class=\"n\">offsets</span><span class=\"p\">]),</span>\n",
       "        <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">expand_dims</span><span class=\"p\">(</span>\n",
       "            <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">stack</span><span class=\"p\">([</span><span class=\"n\">source</span><span class=\"p\">[</span><span class=\"n\">idx</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">:</span><span class=\"n\">idx</span> <span class=\"o\">+</span> <span class=\"n\">seq_len</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">idx</span> <span class=\"ow\">in</span> <span class=\"n\">offsets</span><span class=\"p\">]),</span>\n",
       "            <span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">),</span>\n",
       "    <span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"n\">six</span><span class=\"o\">.</span><span class=\"n\">next</span><span class=\"p\">(</span><span class=\"n\">training_generator</span><span class=\"p\">(</span><span class=\"n\">seq_len</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">))</span>\n",
       "</pre></div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
       "</div><div class=\"inner_cell\">\n",
       "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
       "<h3 id=\"Build-the-model\">Build the model<a class=\"anchor-link\" href=\"#Build-the-model\">¶</a></h3><p>The model is defined as a two-layer, forward-LSTMâ€”with two changes from the <code>tf.keras</code> standard LSTM definition:</p>\n",
       "<ol>\n",
       "<li>Define the input <code>shape</code> of the model to comply with the <a href=\"https://www.tensorflow.org/performance/xla/\">XLA compiler</a>'s static shape requirement.</li>\n",
       "<li>Use <code>tf.train.Optimizer</code> instead of a standard Keras optimizer (Keras optimizer support is still experimental).</li>\n",
       "</ol>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cell border-box-sizing code_cell rendered\">\n",
       "<div class=\"input\">\n",
       "<div class=\"prompt input_prompt\">In [0]:</div>\n",
       "<div class=\"inner_cell\">\n",
       "<div class=\"input_area\">\n",
       "<div class=\" highlight hl-ipython3\"><pre><span></span><span class=\"n\">EMBEDDING_DIM</span> <span class=\"o\">=</span> <span class=\"mi\">512</span>\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">lstm_model</span><span class=\"p\">(</span><span class=\"n\">seq_len</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"n\">stateful</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">):</span>\n",
       "  <span class=\"sd\">\"\"\"Language model: predict the next word given the current word.\"\"\"</span>\n",
       "  <span class=\"n\">source</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">Input</span><span class=\"p\">(</span>\n",
       "      <span class=\"n\">name</span><span class=\"o\">=</span><span class=\"s1\">'seed'</span><span class=\"p\">,</span> <span class=\"n\">shape</span><span class=\"o\">=</span><span class=\"p\">(</span><span class=\"n\">seq_len</span><span class=\"p\">,),</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"n\">batch_size</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">int32</span><span class=\"p\">)</span>\n",
       "\n",
       "  <span class=\"n\">embedding</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Embedding</span><span class=\"p\">(</span><span class=\"n\">input_dim</span><span class=\"o\">=</span><span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"n\">output_dim</span><span class=\"o\">=</span><span class=\"n\">EMBEDDING_DIM</span><span class=\"p\">)(</span><span class=\"n\">source</span><span class=\"p\">)</span>\n",
       "  <span class=\"n\">lstm_1</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">LSTM</span><span class=\"p\">(</span><span class=\"n\">EMBEDDING_DIM</span><span class=\"p\">,</span> <span class=\"n\">stateful</span><span class=\"o\">=</span><span class=\"n\">stateful</span><span class=\"p\">,</span> <span class=\"n\">return_sequences</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)(</span><span class=\"n\">embedding</span><span class=\"p\">)</span>\n",
       "  <span class=\"n\">lstm_2</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">LSTM</span><span class=\"p\">(</span><span class=\"n\">EMBEDDING_DIM</span><span class=\"p\">,</span> <span class=\"n\">stateful</span><span class=\"o\">=</span><span class=\"n\">stateful</span><span class=\"p\">,</span> <span class=\"n\">return_sequences</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)(</span><span class=\"n\">lstm_1</span><span class=\"p\">)</span>\n",
       "  <span class=\"n\">predicted_char</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">TimeDistributed</span><span class=\"p\">(</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">layers</span><span class=\"o\">.</span><span class=\"n\">Dense</span><span class=\"p\">(</span><span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"n\">activation</span><span class=\"o\">=</span><span class=\"s1\">'softmax'</span><span class=\"p\">))(</span><span class=\"n\">lstm_2</span><span class=\"p\">)</span>\n",
       "  <span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">Model</span><span class=\"p\">(</span><span class=\"n\">inputs</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">source</span><span class=\"p\">],</span> <span class=\"n\">outputs</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"n\">predicted_char</span><span class=\"p\">])</span>\n",
       "  <span class=\"n\">model</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span>\n",
       "      <span class=\"n\">optimizer</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">train</span><span class=\"o\">.</span><span class=\"n\">RMSPropOptimizer</span><span class=\"p\">(</span><span class=\"n\">learning_rate</span><span class=\"o\">=</span><span class=\"mf\">0.01</span><span class=\"p\">),</span>\n",
       "      <span class=\"n\">loss</span><span class=\"o\">=</span><span class=\"s1\">'sparse_categorical_crossentropy'</span><span class=\"p\">,</span>\n",
       "      <span class=\"n\">metrics</span><span class=\"o\">=</span><span class=\"p\">[</span><span class=\"s1\">'sparse_categorical_accuracy'</span><span class=\"p\">])</span>\n",
       "  <span class=\"k\">return</span> <span class=\"n\">model</span>\n",
       "</pre></div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
       "</div><div class=\"inner_cell\">\n",
       "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
       "<h3 id=\"Train-the-model\">Train the model<a class=\"anchor-link\" href=\"#Train-the-model\">¶</a></h3><p>The <code>tf.contrib.tpu.keras_to_tpu_model</code> function converts a <code>tf.keras</code> model to an equivalent TPU version. You then use the standard Keras methods to train: <code>fit</code>, <code>predict</code>, and <code>evaluate</code>.</p>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cell border-box-sizing code_cell rendered\">\n",
       "<div class=\"input\">\n",
       "<div class=\"prompt input_prompt\">In [0]:</div>\n",
       "<div class=\"inner_cell\">\n",
       "<div class=\"input_area\">\n",
       "<div class=\" highlight hl-ipython3\"><pre><span></span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">keras</span><span class=\"o\">.</span><span class=\"n\">backend</span><span class=\"o\">.</span><span class=\"n\">clear_session</span><span class=\"p\">()</span>\n",
       "\n",
       "<span class=\"n\">training_model</span> <span class=\"o\">=</span> <span class=\"n\">lstm_model</span><span class=\"p\">(</span><span class=\"n\">seq_len</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">stateful</span><span class=\"o\">=</span><span class=\"kc\">False</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"n\">tpu_model</span> <span class=\"o\">=</span> <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">contrib</span><span class=\"o\">.</span><span class=\"n\">tpu</span><span class=\"o\">.</span><span class=\"n\">keras_to_tpu_model</span><span class=\"p\">(</span>\n",
       "    <span class=\"n\">training_model</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">strategy</span><span class=\"o\">=</span><span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">contrib</span><span class=\"o\">.</span><span class=\"n\">tpu</span><span class=\"o\">.</span><span class=\"n\">TPUDistributionStrategy</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">tf</span><span class=\"o\">.</span><span class=\"n\">contrib</span><span class=\"o\">.</span><span class=\"n\">cluster_resolver</span><span class=\"o\">.</span><span class=\"n\">TPUClusterResolver</span><span class=\"p\">(</span><span class=\"n\">TPU_WORKER</span><span class=\"p\">)))</span>\n",
       "\n",
       "<span class=\"n\">tpu_model</span><span class=\"o\">.</span><span class=\"n\">fit_generator</span><span class=\"p\">(</span>\n",
       "    <span class=\"n\">training_generator</span><span class=\"p\">(</span><span class=\"n\">seq_len</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"mi\">1024</span><span class=\"p\">),</span>\n",
       "    <span class=\"n\">steps_per_epoch</span><span class=\"o\">=</span><span class=\"mi\">100</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">epochs</span><span class=\"o\">=</span><span class=\"mi\">10</span><span class=\"p\">,</span>\n",
       "<span class=\"p\">)</span>\n",
       "<span class=\"n\">tpu_model</span><span class=\"o\">.</span><span class=\"n\">save_weights</span><span class=\"p\">(</span><span class=\"s1\">'/tmp/bard.h5'</span><span class=\"p\">,</span> <span class=\"n\">overwrite</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n",
       "</pre></div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
       "</div><div class=\"inner_cell\">\n",
       "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
       "<h3 id=\"Make-predictions-with-the-model\">Make predictions with the model<a class=\"anchor-link\" href=\"#Make-predictions-with-the-model\">¶</a></h3><p>Use the trained model to make predictions and generate your own Shakespeare-esque play.\n",
       "Start the model off with a <em>seed</em> sentence, then generate 250 characters from it. The model makes five predictions from the initial seed.</p>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cell border-box-sizing code_cell rendered\">\n",
       "<div class=\"input\">\n",
       "<div class=\"prompt input_prompt\">In [0]:</div>\n",
       "<div class=\"inner_cell\">\n",
       "<div class=\"input_area\">\n",
       "<div class=\" highlight hl-ipython3\"><pre><span></span><span class=\"n\">BATCH_SIZE</span> <span class=\"o\">=</span> <span class=\"mi\">5</span>\n",
       "<span class=\"n\">PREDICT_LEN</span> <span class=\"o\">=</span> <span class=\"mi\">250</span>\n",
       "\n",
       "<span class=\"c1\"># Keras requires the batch size be specified ahead of time for stateful models.</span>\n",
       "<span class=\"c1\"># We use a sequence length of 1, as we will be feeding in one character at a </span>\n",
       "<span class=\"c1\"># time and predicting the next character.</span>\n",
       "<span class=\"n\">prediction_model</span> <span class=\"o\">=</span> <span class=\"n\">lstm_model</span><span class=\"p\">(</span><span class=\"n\">seq_len</span><span class=\"o\">=</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">batch_size</span><span class=\"o\">=</span><span class=\"n\">BATCH_SIZE</span><span class=\"p\">,</span> <span class=\"n\">stateful</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">prediction_model</span><span class=\"o\">.</span><span class=\"n\">load_weights</span><span class=\"p\">(</span><span class=\"s1\">'/tmp/bard.h5'</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># We seed the model with our initial string, copied BATCH_SIZE times</span>\n",
       "\n",
       "<span class=\"n\">seed_txt</span> <span class=\"o\">=</span> <span class=\"s1\">'Looks it not like the king?  Verily, we must go! '</span>\n",
       "<span class=\"n\">seed</span> <span class=\"o\">=</span> <span class=\"n\">transform</span><span class=\"p\">(</span><span class=\"n\">seed_txt</span><span class=\"p\">)</span>\n",
       "<span class=\"n\">seed</span> <span class=\"o\">=</span> <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">repeat</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">expand_dims</span><span class=\"p\">(</span><span class=\"n\">seed</span><span class=\"p\">,</span> <span class=\"mi\">0</span><span class=\"p\">),</span> <span class=\"n\">BATCH_SIZE</span><span class=\"p\">,</span> <span class=\"n\">axis</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n",
       "\n",
       "<span class=\"c1\"># First, run the seed forward to prime the state of the model.</span>\n",
       "<span class=\"n\">prediction_model</span><span class=\"o\">.</span><span class=\"n\">reset_states</span><span class=\"p\">()</span>\n",
       "<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">seed_txt</span><span class=\"p\">)</span> <span class=\"o\">-</span> <span class=\"mi\">1</span><span class=\"p\">):</span>\n",
       "  <span class=\"n\">prediction_model</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">seed</span><span class=\"p\">[:,</span> <span class=\"n\">i</span><span class=\"p\">:</span><span class=\"n\">i</span> <span class=\"o\">+</span> <span class=\"mi\">1</span><span class=\"p\">])</span>\n",
       "\n",
       "<span class=\"c1\"># Now we can accumulate predictions!</span>\n",
       "<span class=\"n\">predictions</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">seed</span><span class=\"p\">[:,</span> <span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">:]]</span>\n",
       "<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">PREDICT_LEN</span><span class=\"p\">):</span>\n",
       "  <span class=\"n\">last_word</span> <span class=\"o\">=</span> <span class=\"n\">predictions</span><span class=\"p\">[</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">]</span>\n",
       "  <span class=\"n\">next_probits</span> <span class=\"o\">=</span> <span class=\"n\">prediction_model</span><span class=\"o\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">last_word</span><span class=\"p\">)[:,</span> <span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"p\">:]</span>\n",
       "  \n",
       "  <span class=\"c1\"># sample from our output distribution</span>\n",
       "  <span class=\"n\">next_idx</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\n",
       "      <span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">random</span><span class=\"o\">.</span><span class=\"n\">choice</span><span class=\"p\">(</span><span class=\"mi\">256</span><span class=\"p\">,</span> <span class=\"n\">p</span><span class=\"o\">=</span><span class=\"n\">next_probits</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">])</span>\n",
       "      <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">BATCH_SIZE</span><span class=\"p\">)</span>\n",
       "  <span class=\"p\">]</span>\n",
       "  <span class=\"n\">predictions</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">asarray</span><span class=\"p\">(</span><span class=\"n\">next_idx</span><span class=\"p\">,</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"n\">np</span><span class=\"o\">.</span><span class=\"n\">int32</span><span class=\"p\">))</span>\n",
       "  \n",
       "\n",
       "<span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">BATCH_SIZE</span><span class=\"p\">):</span>\n",
       "  <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"s1\">'PREDICTION </span><span class=\"si\">%d</span><span class=\"se\">\\n\\n</span><span class=\"s1\">'</span> <span class=\"o\">%</span> <span class=\"n\">i</span><span class=\"p\">)</span>\n",
       "  <span class=\"n\">p</span> <span class=\"o\">=</span> <span class=\"p\">[</span><span class=\"n\">predictions</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">][</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"k\">for</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"n\">PREDICT_LEN</span><span class=\"p\">)]</span>\n",
       "  <span class=\"n\">generated</span> <span class=\"o\">=</span> <span class=\"s1\">''</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">([</span><span class=\"nb\">chr</span><span class=\"p\">(</span><span class=\"n\">c</span><span class=\"p\">)</span> <span class=\"k\">for</span> <span class=\"n\">c</span> <span class=\"ow\">in</span> <span class=\"n\">p</span><span class=\"p\">])</span>\n",
       "  <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">generated</span><span class=\"p\">)</span>\n",
       "  <span class=\"nb\">print</span><span class=\"p\">()</span>\n",
       "  <span class=\"k\">assert</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">generated</span><span class=\"p\">)</span> <span class=\"o\">==</span> <span class=\"n\">PREDICT_LEN</span><span class=\"p\">,</span> <span class=\"s1\">'Generated text too short'</span>\n",
       "</pre></div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"cell border-box-sizing text_cell rendered\"><div class=\"prompt input_prompt\">\n",
       "</div><div class=\"inner_cell\">\n",
       "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
       "<h2 id=\"What's-next\">What's next<a class=\"anchor-link\" href=\"#What's-next\">¶</a></h2><ul>\n",
       "<li>Learn about <a href=\"https://cloud.google.com/tpu/docs\">Cloud TPUs</a> that Google designed and optimized specifically to speed up and scale up ML workloads for training and inference and to enable ML engineers and researchers to iterate more quickly.</li>\n",
       "<li>Explore the range of <a href=\"https://cloud.google.com/tpu/docs/tutorials\">Cloud TPU tutorials and Colabs</a> to find other examples that can be used when implementing your ML project.</li>\n",
       "</ul>\n",
       "<p>On Google Cloud Platform, in addition to GPUs and TPUs available on pre-configured <a href=\"https://cloud.google.com/deep-learning-vm/\">deep learning VMs</a>,  you will find <a href=\"https://cloud.google.com/automl/\">AutoML</a><em>(beta)</em> for training custom models without writing code and <a href=\"https://cloud.google.com/ml-engine/docs/\">Cloud ML Engine</a> which will allows you to run parallel trainings and hyperparameter tuning of your custom models on powerful distributed hardware.</p>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</body>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(document1, \"r\") as f:\n",
    "    content1 = (f.read())\n",
    "    \n",
    "content1 = soup(content1, 'html.parser')\n",
    "content1.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_content = content1.findAll(\"div\", {\"class\": \"cell border-box-sizing text_cell rendered\"})\n",
    "page1 = \"\"\n",
    "len(page_content)\n",
    "for every_content in page_content:\n",
    "    page1 +=((re.sub(r'[^a-zA-Z0-9 ]',r' ',(str(every_content.text)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens1 = word_tokenize(page1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "document2 = requests.get('https://playground.tensorflow.org')\n",
    "content2 = soup(document2.text, 'html.parser')\n",
    "page2 = re.sub(r'[^a-zA-Z ]',r' ', (content2.body.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens2 = word_tokenize(page2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok2 =[word.lower() for word in tokens2]\n",
    "tok1 =[word.lower() for word in tokens1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'kera' in tok2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = list(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(word):\n",
    "    regexp = r'^(.*?)(ing|ly|ed|ious|ies|ive|ment)?$'\n",
    "    stem, suffix = re.findall(regexp, word)[0]\n",
    "    return stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "def snow_stem(word):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    return stemmer.stem(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def improve_abbrevations(word):\n",
    "    abbre_words= {'kera':'keras','tf': 'tensorflow', 'tpu':'tensor processing unit', 'tpus':'tensor processing unit', 'ml':'machine learning'}\n",
    "    if word in abbre_words:\n",
    "        right_word = abbre_words[word]\n",
    "        return right_word\n",
    "    else:\n",
    "        return word\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = tok1 +tok2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [word for word in combined if word not in stopwords_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('copyright', 'NN'),\n",
       " ('2018', 'CD'),\n",
       " ('tensorflow', 'NN'),\n",
       " ('hub', 'NN'),\n",
       " ('authors', 'NNS'),\n",
       " ('licensed', 'VBD'),\n",
       " ('apache', 'NN'),\n",
       " ('license', 'NN'),\n",
       " ('version', 'NN'),\n",
       " ('2', 'CD'),\n",
       " ('0', 'CD'),\n",
       " ('license', 'NN'),\n",
       " ('predict', 'NN'),\n",
       " ('shakespeare', 'NN'),\n",
       " ('cloud', 'NN'),\n",
       " ('tpus', 'NN'),\n",
       " ('keras', 'FW'),\n",
       " ('overview', 'NN'),\n",
       " ('example', 'NN'),\n",
       " ('uses', 'VBZ'),\n",
       " ('tf', 'JJ'),\n",
       " ('keras', 'NNS'),\n",
       " ('build', 'VBP'),\n",
       " ('language', 'NN'),\n",
       " ('model', 'NN'),\n",
       " ('train', 'VBP'),\n",
       " ('cloud', 'JJ'),\n",
       " ('tpu', 'NN'),\n",
       " ('language', 'NN'),\n",
       " ('model', 'NN'),\n",
       " ('predicts', 'VBZ'),\n",
       " ('next', 'JJ'),\n",
       " ('character', 'NN'),\n",
       " ('text', 'NN'),\n",
       " ('given', 'VBN'),\n",
       " ('text', 'JJ'),\n",
       " ('far', 'RB'),\n",
       " ('trained', 'JJ'),\n",
       " ('model', 'NN'),\n",
       " ('generate', 'VB'),\n",
       " ('new', 'JJ'),\n",
       " ('snippets', 'NNS'),\n",
       " ('text', 'JJ'),\n",
       " ('read', 'JJ'),\n",
       " ('similar', 'JJ'),\n",
       " ('style', 'NN'),\n",
       " ('text', 'NN'),\n",
       " ('training', 'NN'),\n",
       " ('data', 'NNS'),\n",
       " ('model', 'NN'),\n",
       " ('trains', 'VBZ'),\n",
       " ('10', 'CD'),\n",
       " ('epochs', 'NN'),\n",
       " ('completes', 'NNS'),\n",
       " ('approximately', 'RB'),\n",
       " ('5', 'CD'),\n",
       " ('minutes', 'NNS'),\n",
       " ('notebook', 'RB'),\n",
       " ('hosted', 'VBD'),\n",
       " ('github', 'JJ'),\n",
       " ('view', 'NN'),\n",
       " ('original', 'JJ'),\n",
       " ('repository', 'NN'),\n",
       " ('opening', 'VBG'),\n",
       " ('notebook', 'NN'),\n",
       " ('select', 'NN'),\n",
       " ('file', 'NN'),\n",
       " ('view', 'NN'),\n",
       " ('github', 'NN'),\n",
       " ('learning', 'VBG'),\n",
       " ('objectives', 'NNS'),\n",
       " ('colab', 'NN'),\n",
       " ('learn', 'VBP'),\n",
       " ('build', 'VB'),\n",
       " ('two', 'CD'),\n",
       " ('layer', 'JJ'),\n",
       " ('forward', 'RB'),\n",
       " ('lstm', 'JJ'),\n",
       " ('model', 'NN'),\n",
       " ('convert', 'NN'),\n",
       " ('tf', 'NN'),\n",
       " ('keras', 'NNS'),\n",
       " ('model', 'FW'),\n",
       " ('equivalent', 'JJ'),\n",
       " ('tpu', 'NN'),\n",
       " ('version', 'NN'),\n",
       " ('use', 'VB'),\n",
       " ('standard', 'JJ'),\n",
       " ('keras', 'NNS'),\n",
       " ('methods', 'NNS'),\n",
       " ('train', 'VBP'),\n",
       " ('fit', 'JJ'),\n",
       " ('predict', 'NN'),\n",
       " ('evaluate', 'NN'),\n",
       " ('use', 'NN'),\n",
       " ('trained', 'VBD'),\n",
       " ('model', 'NNS'),\n",
       " ('make', 'VBP'),\n",
       " ('predictions', 'NNS'),\n",
       " ('generate', 'VB'),\n",
       " ('shakespeare', 'NN'),\n",
       " ('esque', 'JJ'),\n",
       " ('play', 'NN'),\n",
       " ('instructions', 'NNS'),\n",
       " ('train', 'VBP'),\n",
       " ('tpu', 'JJ'),\n",
       " ('main', 'JJ'),\n",
       " ('menu', 'NN'),\n",
       " ('click', 'NN'),\n",
       " ('runtime', 'NN'),\n",
       " ('select', 'JJ'),\n",
       " ('change', 'NN'),\n",
       " ('runtime', 'NN'),\n",
       " ('type', 'NN'),\n",
       " ('set', 'VBN'),\n",
       " ('tpu', 'NN'),\n",
       " ('hardware', 'NN'),\n",
       " ('accelerator', 'NN'),\n",
       " ('click', 'NN'),\n",
       " ('runtime', 'NN'),\n",
       " ('select', 'JJ'),\n",
       " ('runtime', 'NN'),\n",
       " ('run', 'NN'),\n",
       " ('also', 'RB'),\n",
       " ('run', 'VBP'),\n",
       " ('cells', 'NNS'),\n",
       " ('manually', 'RB'),\n",
       " ('shift', 'VBP'),\n",
       " ('enter', 'RB'),\n",
       " ('tpus', 'RB'),\n",
       " ('located', 'VBN'),\n",
       " ('google', 'NN'),\n",
       " ('cloud', 'NN'),\n",
       " ('optimal', 'JJ'),\n",
       " ('performance', 'NN'),\n",
       " ('read', 'NN'),\n",
       " ('data', 'NNS'),\n",
       " ('directly', 'RB'),\n",
       " ('google', 'VBP'),\n",
       " ('cloud', 'JJ'),\n",
       " ('storage', 'NN'),\n",
       " ('gcs', 'NN'),\n",
       " ('data', 'NNS'),\n",
       " ('model', 'NN'),\n",
       " ('training', 'NN'),\n",
       " ('example', 'NN'),\n",
       " ('train', 'VBP'),\n",
       " ('model', 'NN'),\n",
       " ('combined', 'VBN'),\n",
       " ('works', 'NNS'),\n",
       " ('william', 'RBR'),\n",
       " ('shakespeare', 'NN'),\n",
       " ('use', 'NN'),\n",
       " ('model', 'NN'),\n",
       " ('compose', 'JJ'),\n",
       " ('play', 'NN'),\n",
       " ('style', 'NN'),\n",
       " ('great', 'JJ'),\n",
       " ('bard', 'NN'),\n",
       " ('loves', 'VBZ'),\n",
       " ('led', 'VBN'),\n",
       " ('dumbs', 'NNS'),\n",
       " ('lack', 'VBP'),\n",
       " ('berjoy', 'JJ'),\n",
       " ('face', 'NN'),\n",
       " ('day', 'NN'),\n",
       " ('spirits', 'VBZ'),\n",
       " ('roar', 'NN'),\n",
       " ('shames', 'NNS'),\n",
       " ('within', 'IN'),\n",
       " ('powers', 'NNS'),\n",
       " ('tied', 'JJ'),\n",
       " ('remedies', 'NNS'),\n",
       " ('lending', 'VBG'),\n",
       " ('occasion', 'NN'),\n",
       " ('loud', 'JJ'),\n",
       " ('lancaster', 'NN'),\n",
       " ('stabb', 'NN'),\n",
       " ('upon', 'IN'),\n",
       " ('sword', 'NN'),\n",
       " ('ever', 'RB'),\n",
       " ('agripo', 'RB'),\n",
       " ('er', 'JJ'),\n",
       " ('days', 'NNS'),\n",
       " ('let', 'VB'),\n",
       " ('free', 'JJ'),\n",
       " ('stop', 'VB'),\n",
       " ('word', 'NN'),\n",
       " ('lear', 'IN'),\n",
       " ('profess', 'JJ'),\n",
       " ('hour', 'NN'),\n",
       " ('stranger', 'NN'),\n",
       " ('life', 'NN'),\n",
       " ('sink', 'VBP'),\n",
       " ('cried', 'VBN'),\n",
       " ('aught', 'JJ'),\n",
       " ('beds', 'NNS'),\n",
       " ('seeks', 'VBZ'),\n",
       " ('chaste', 'NN'),\n",
       " ('senses', 'NNS'),\n",
       " ('prove', 'VBP'),\n",
       " ('burning', 'VBG'),\n",
       " ('perforces', 'NNS'),\n",
       " ('seen', 'VBN'),\n",
       " ('eyes', 'NNS'),\n",
       " ('fast', 'RB'),\n",
       " ('download', 'JJ'),\n",
       " ('data', 'NNS'),\n",
       " ('download', 'NN'),\n",
       " ('complete', 'JJ'),\n",
       " ('works', 'VBZ'),\n",
       " ('william', 'WDT'),\n",
       " ('shakespeare', 'NN'),\n",
       " ('single', 'JJ'),\n",
       " ('text', 'NN'),\n",
       " ('file', 'NN'),\n",
       " ('project', 'NN'),\n",
       " ('gutenberg', 'NN'),\n",
       " ('use', 'NN'),\n",
       " ('snippets', 'NNS'),\n",
       " ('file', 'VBP'),\n",
       " ('training', 'VBG'),\n",
       " ('data', 'NNS'),\n",
       " ('model', 'NN'),\n",
       " ('target', 'NN'),\n",
       " ('snippet', 'JJ'),\n",
       " ('offset', 'VB'),\n",
       " ('one', 'CD'),\n",
       " ('character', 'NN'),\n",
       " ('build', 'NN'),\n",
       " ('data', 'NNS'),\n",
       " ('generator', 'NN'),\n",
       " ('build', 'VBP'),\n",
       " ('model', 'NN'),\n",
       " ('model', 'NN'),\n",
       " ('defined', 'VBD'),\n",
       " ('two', 'CD'),\n",
       " ('layer', 'NN'),\n",
       " ('forward', 'RB'),\n",
       " ('lstm', 'VBZ'),\n",
       " ('two', 'CD'),\n",
       " ('changes', 'NNS'),\n",
       " ('tf', 'VBP'),\n",
       " ('keras', 'VB'),\n",
       " ('standard', 'JJ'),\n",
       " ('lstm', 'NN'),\n",
       " ('definition', 'NN'),\n",
       " ('define', 'NN'),\n",
       " ('input', 'NN'),\n",
       " ('shape', 'NN'),\n",
       " ('model', 'NN'),\n",
       " ('comply', 'NN'),\n",
       " ('xla', 'NNP'),\n",
       " ('compiler', 'NN'),\n",
       " ('static', 'JJ'),\n",
       " ('shape', 'NN'),\n",
       " ('requirement', 'NN'),\n",
       " ('use', 'NN'),\n",
       " ('tf', 'NN'),\n",
       " ('train', 'VBP'),\n",
       " ('optimizer', 'NN'),\n",
       " ('instead', 'RB'),\n",
       " ('standard', 'JJ'),\n",
       " ('keras', 'NNS'),\n",
       " ('optimizer', 'VBP'),\n",
       " ('keras', 'NNS'),\n",
       " ('optimizer', 'VBP'),\n",
       " ('support', 'NN'),\n",
       " ('still', 'RB'),\n",
       " ('experimental', 'JJ'),\n",
       " ('train', 'NN'),\n",
       " ('model', 'NN'),\n",
       " ('tf', 'NN'),\n",
       " ('contrib', 'NN'),\n",
       " ('tpu', 'NN'),\n",
       " ('keras', 'FW'),\n",
       " ('tpu', 'JJ'),\n",
       " ('model', 'NN'),\n",
       " ('function', 'NN'),\n",
       " ('converts', 'NNS'),\n",
       " ('tf', 'VBP'),\n",
       " ('keras', 'NNS'),\n",
       " ('model', 'FW'),\n",
       " ('equivalent', 'JJ'),\n",
       " ('tpu', 'NN'),\n",
       " ('version', 'NN'),\n",
       " ('use', 'VB'),\n",
       " ('standard', 'JJ'),\n",
       " ('keras', 'NNS'),\n",
       " ('methods', 'NNS'),\n",
       " ('train', 'VBP'),\n",
       " ('fit', 'JJ'),\n",
       " ('predict', 'NN'),\n",
       " ('evaluate', 'NN'),\n",
       " ('make', 'VBP'),\n",
       " ('predictions', 'NNS'),\n",
       " ('model', 'NN'),\n",
       " ('use', 'NN'),\n",
       " ('trained', 'VBD'),\n",
       " ('model', 'NNS'),\n",
       " ('make', 'VBP'),\n",
       " ('predictions', 'NNS'),\n",
       " ('generate', 'VB'),\n",
       " ('shakespeare', 'NN'),\n",
       " ('esque', 'JJ'),\n",
       " ('play', 'VB'),\n",
       " ('start', 'JJ'),\n",
       " ('model', 'NN'),\n",
       " ('seed', 'NN'),\n",
       " ('sentence', 'NN'),\n",
       " ('generate', 'NN'),\n",
       " ('250', 'CD'),\n",
       " ('characters', 'NNS'),\n",
       " ('model', 'NN'),\n",
       " ('makes', 'VBZ'),\n",
       " ('five', 'CD'),\n",
       " ('predictions', 'NNS'),\n",
       " ('initial', 'JJ'),\n",
       " ('seed', 'NN'),\n",
       " ('next', 'IN'),\n",
       " ('learn', 'JJ'),\n",
       " ('cloud', 'NN'),\n",
       " ('tpus', 'NN'),\n",
       " ('google', 'NN'),\n",
       " ('designed', 'VBN'),\n",
       " ('optimized', 'VBN'),\n",
       " ('specifically', 'RB'),\n",
       " ('speed', 'VB'),\n",
       " ('scale', 'JJ'),\n",
       " ('ml', 'NN'),\n",
       " ('workloads', 'NNS'),\n",
       " ('training', 'VBG'),\n",
       " ('inference', 'NN'),\n",
       " ('enable', 'JJ'),\n",
       " ('ml', 'NN'),\n",
       " ('engineers', 'NNS'),\n",
       " ('researchers', 'NNS'),\n",
       " ('iterate', 'VBP'),\n",
       " ('quickly', 'RB'),\n",
       " ('explore', 'RB'),\n",
       " ('range', 'JJ'),\n",
       " ('cloud', 'NN'),\n",
       " ('tpu', 'NN'),\n",
       " ('tutorials', 'NNS'),\n",
       " ('colabs', 'VBP'),\n",
       " ('find', 'VBP'),\n",
       " ('examples', 'NNS'),\n",
       " ('used', 'VBN'),\n",
       " ('implementing', 'VBG'),\n",
       " ('ml', 'NN'),\n",
       " ('project', 'NN'),\n",
       " ('google', 'NN'),\n",
       " ('cloud', 'NN'),\n",
       " ('platform', 'NN'),\n",
       " ('addition', 'NN'),\n",
       " ('gpus', 'NN'),\n",
       " ('tpus', 'NN'),\n",
       " ('available', 'JJ'),\n",
       " ('pre', 'NN'),\n",
       " ('configured', 'VBD'),\n",
       " ('deep', 'JJ'),\n",
       " ('learning', 'NN'),\n",
       " ('vms', 'JJ'),\n",
       " ('find', 'VBP'),\n",
       " ('automl', 'JJ'),\n",
       " ('beta', 'NN'),\n",
       " ('training', 'NN'),\n",
       " ('custom', 'NN'),\n",
       " ('models', 'NNS'),\n",
       " ('without', 'IN'),\n",
       " ('writing', 'VBG'),\n",
       " ('code', 'NN'),\n",
       " ('cloud', 'NN'),\n",
       " ('ml', 'NN'),\n",
       " ('engine', 'NN'),\n",
       " ('allows', 'VBZ'),\n",
       " ('run', 'VBP'),\n",
       " ('parallel', 'JJ'),\n",
       " ('trainings', 'NNS'),\n",
       " ('hyperparameter', 'RBR'),\n",
       " ('tuning', 'VBG'),\n",
       " ('custom', 'NN'),\n",
       " ('models', 'NNS'),\n",
       " ('powerful', 'JJ'),\n",
       " ('distributed', 'VBN'),\n",
       " ('hardware', 'NN'),\n",
       " ('tinker', 'NN'),\n",
       " ('neural', 'JJ'),\n",
       " ('network', 'NN'),\n",
       " ('right', 'RB'),\n",
       " ('browser', 'NN'),\n",
       " ('worry', 'VBP'),\n",
       " ('break', 'JJ'),\n",
       " ('promise', 'NN'),\n",
       " ('replay', 'NN'),\n",
       " ('play', 'NN'),\n",
       " ('arrow', 'NN'),\n",
       " ('pause', 'IN'),\n",
       " ('skip', 'JJ'),\n",
       " ('next', 'JJ'),\n",
       " ('epoch', 'NN'),\n",
       " ('learning', 'VBG'),\n",
       " ('rate', 'NN'),\n",
       " ('activation', 'NN'),\n",
       " ('relu', 'NN'),\n",
       " ('tanh', 'NN'),\n",
       " ('sigmoid', 'JJ'),\n",
       " ('linear', 'JJ'),\n",
       " ('regularization', 'NN'),\n",
       " ('none', 'NN'),\n",
       " ('l', 'NN'),\n",
       " ('l', 'JJ'),\n",
       " ('regularization', 'NN'),\n",
       " ('rate', 'NN'),\n",
       " ('problem', 'NN'),\n",
       " ('type', 'NN'),\n",
       " ('classification', 'NN'),\n",
       " ('regression', 'NN'),\n",
       " ('data', 'NNS'),\n",
       " ('dataset', 'NN'),\n",
       " ('want', 'VBP'),\n",
       " ('use', 'NN'),\n",
       " ('ratio', 'NN'),\n",
       " ('training', 'VBG'),\n",
       " ('test', 'NN'),\n",
       " ('data', 'NNS'),\n",
       " ('xx', 'NNP'),\n",
       " ('noise', 'NN'),\n",
       " ('xx', 'NNP'),\n",
       " ('batch', 'NN'),\n",
       " ('size', 'NN'),\n",
       " ('xx', 'NNP'),\n",
       " ('regenerate', 'NN'),\n",
       " ('features', 'NNS'),\n",
       " ('properties', 'NNS'),\n",
       " ('want', 'VBP'),\n",
       " ('feed', 'NN'),\n",
       " ('click', 'NN'),\n",
       " ('anywhere', 'RB'),\n",
       " ('edit', 'RB'),\n",
       " ('weight', 'JJ'),\n",
       " ('bias', 'NN'),\n",
       " ('output', 'NN'),\n",
       " ('one', 'CD'),\n",
       " ('neuron', 'NN'),\n",
       " ('hover', 'NN'),\n",
       " ('see', 'VBP'),\n",
       " ('larger', 'JJR'),\n",
       " ('outputs', 'NNS'),\n",
       " ('mixed', 'JJ'),\n",
       " ('varying', 'VBG'),\n",
       " ('weights', 'NNS'),\n",
       " ('shown', 'VBN'),\n",
       " ('thickness', 'JJ'),\n",
       " ('lines', 'NNS'),\n",
       " ('add', 'VBP'),\n",
       " ('remove', 'VB'),\n",
       " ('output', 'NN'),\n",
       " ('test', 'NN'),\n",
       " ('loss', 'NN'),\n",
       " ('training', 'NN'),\n",
       " ('loss', 'NN'),\n",
       " ('colors', 'NNS'),\n",
       " ('shows', 'VBZ'),\n",
       " ('data', 'NNS'),\n",
       " ('neuron', 'RB'),\n",
       " ('weight', 'VBD'),\n",
       " ('values', 'NNS'),\n",
       " ('show', 'VBP'),\n",
       " ('test', 'NN'),\n",
       " ('data', 'NNS'),\n",
       " ('discretize', 'NN'),\n",
       " ('output', 'NN'),\n",
       " ('keyboard', 'NN'),\n",
       " ('arrow', 'NN'),\n",
       " ('um', 'JJ'),\n",
       " ('neural', 'JJ'),\n",
       " ('network', 'NN'),\n",
       " ('technique', 'NN'),\n",
       " ('building', 'NN'),\n",
       " ('computer', 'NN'),\n",
       " ('program', 'NN'),\n",
       " ('learns', 'VBZ'),\n",
       " ('data', 'NNS'),\n",
       " ('based', 'VBN'),\n",
       " ('loosely', 'RB'),\n",
       " ('think', 'VBP'),\n",
       " ('human', 'JJ'),\n",
       " ('brain', 'NN'),\n",
       " ('works', 'NNS'),\n",
       " ('first', 'JJ'),\n",
       " ('collection', 'NN'),\n",
       " ('software', 'NN'),\n",
       " ('neurons', 'NNS'),\n",
       " ('created', 'VBD'),\n",
       " ('connected', 'VBN'),\n",
       " ('together', 'RB'),\n",
       " ('allowing', 'VBG'),\n",
       " ('send', 'JJ'),\n",
       " ('messages', 'NNS'),\n",
       " ('next', 'IN'),\n",
       " ('network', 'NN'),\n",
       " ('asked', 'VBD'),\n",
       " ('solve', 'NN'),\n",
       " ('problem', 'NN'),\n",
       " ('attempts', 'NNS'),\n",
       " ('time', 'NN'),\n",
       " ('strengthening', 'VBG'),\n",
       " ('connections', 'NNS'),\n",
       " ('lead', 'JJ'),\n",
       " ('success', 'NN'),\n",
       " ('diminishing', 'VBG'),\n",
       " ('lead', 'JJ'),\n",
       " ('failure', 'NN'),\n",
       " ('detailed', 'VBN'),\n",
       " ('introduction', 'NN'),\n",
       " ('neural', 'JJ'),\n",
       " ('networks', 'NNS'),\n",
       " ('michael', 'VBP'),\n",
       " ('nielsen', 'JJ'),\n",
       " ('neural', 'JJ'),\n",
       " ('networks', 'NNS'),\n",
       " ('deep', 'RB'),\n",
       " ('learning', 'VBG'),\n",
       " ('good', 'JJ'),\n",
       " ('place', 'NN'),\n",
       " ('start', 'VB'),\n",
       " ('technical', 'JJ'),\n",
       " ('overview', 'NN'),\n",
       " ('try', 'NN'),\n",
       " ('deep', 'JJ'),\n",
       " ('learning', 'NN'),\n",
       " ('ian', 'JJ'),\n",
       " ('goodfellow', 'NN'),\n",
       " ('yoshua', 'NN'),\n",
       " ('bengio', 'NN'),\n",
       " ('aaron', 'NN'),\n",
       " ('courville', 'NN'),\n",
       " ('cool', 'NN'),\n",
       " ('repurpose', 'JJ'),\n",
       " ('please', 'NN'),\n",
       " ('open', 'JJ'),\n",
       " ('sourced', 'VBD'),\n",
       " ('github', 'JJ'),\n",
       " ('hope', 'NN'),\n",
       " ('make', 'VBP'),\n",
       " ('neural', 'JJ'),\n",
       " ('networks', 'NNS'),\n",
       " ('little', 'RB'),\n",
       " ('accessible', 'JJ'),\n",
       " ('easier', 'JJR'),\n",
       " ('learn', 'JJ'),\n",
       " ('free', 'JJ'),\n",
       " ('use', 'NN'),\n",
       " ('way', 'NN'),\n",
       " ('follows', 'VBZ'),\n",
       " ('apache', 'RP'),\n",
       " ('license', 'JJ'),\n",
       " ('suggestions', 'NNS'),\n",
       " ('additions', 'NNS'),\n",
       " ('changes', 'NNS'),\n",
       " ('please', 'VBP'),\n",
       " ('let', 'VB'),\n",
       " ('us', 'PRP'),\n",
       " ('know', 'VB'),\n",
       " ('also', 'RB'),\n",
       " ('provided', 'VBN'),\n",
       " ('controls', 'NNS'),\n",
       " ('enable', 'JJ'),\n",
       " ('tailor', 'NN'),\n",
       " ('playground', 'NN'),\n",
       " ('specific', 'JJ'),\n",
       " ('topic', 'NN'),\n",
       " ('lesson', 'NN'),\n",
       " ('choose', 'JJ'),\n",
       " ('features', 'NNS'),\n",
       " ('like', 'IN'),\n",
       " ('visible', 'JJ'),\n",
       " ('save', 'JJ'),\n",
       " ('link', 'NN'),\n",
       " ('refresh', 'JJ'),\n",
       " ('page', 'NN'),\n",
       " ('colors', 'NNS'),\n",
       " ('mean', 'VBP'),\n",
       " ('orange', 'NN'),\n",
       " ('blue', 'NN'),\n",
       " ('used', 'VBN'),\n",
       " ('throughout', 'IN'),\n",
       " ('visualization', 'NN'),\n",
       " ('slightly', 'RB'),\n",
       " ('different', 'JJ'),\n",
       " ('ways', 'NNS'),\n",
       " ('general', 'JJ'),\n",
       " ('orange', 'NN'),\n",
       " ('shows', 'NNS'),\n",
       " ('negative', 'JJ'),\n",
       " ('values', 'NNS'),\n",
       " ('blue', 'VBP'),\n",
       " ('shows', 'VBZ'),\n",
       " ('positive', 'JJ'),\n",
       " ('values', 'NNS'),\n",
       " ('data', 'NNS'),\n",
       " ('points', 'NNS'),\n",
       " ('represented', 'VBD'),\n",
       " ('small', 'JJ'),\n",
       " ('circles', 'NNS'),\n",
       " ('initially', 'RB'),\n",
       " ('colored', 'VBD'),\n",
       " ('orange', 'JJ'),\n",
       " ('blue', 'JJ'),\n",
       " ('correspond', 'NN'),\n",
       " ('positive', 'JJ'),\n",
       " ('one', 'CD'),\n",
       " ('negative', 'JJ'),\n",
       " ('one', 'CD'),\n",
       " ('hidden', 'NN'),\n",
       " ('layers', 'NNS'),\n",
       " ('lines', 'NNS'),\n",
       " ('colored', 'VBD'),\n",
       " ('weights', 'NNS'),\n",
       " ('connections', 'NNS'),\n",
       " ('neurons', 'NNS'),\n",
       " ('blue', 'VBP'),\n",
       " ('shows', 'NNS'),\n",
       " ('positive', 'JJ'),\n",
       " ('weight', 'NN'),\n",
       " ('means', 'VBZ'),\n",
       " ('network', 'NN'),\n",
       " ('using', 'VBG'),\n",
       " ('output', 'NN'),\n",
       " ('neuron', 'RB'),\n",
       " ('given', 'VBN'),\n",
       " ('orange', 'RP'),\n",
       " ('line', 'NN'),\n",
       " ('shows', 'VBZ'),\n",
       " ('network', 'NN'),\n",
       " ('assiging', 'VBG'),\n",
       " ('negative', 'JJ'),\n",
       " ('weight', 'NN'),\n",
       " ('output', 'NN'),\n",
       " ('layer', 'NN'),\n",
       " ('dots', 'NNS'),\n",
       " ('colored', 'VBD'),\n",
       " ('orange', 'NN'),\n",
       " ('blue', 'NN'),\n",
       " ('depending', 'VBG'),\n",
       " ('original', 'JJ'),\n",
       " ('values', 'NNS'),\n",
       " ('background', 'IN'),\n",
       " ('color', 'NN'),\n",
       " ('shows', 'NNS'),\n",
       " ('network', 'NN'),\n",
       " ('predicting', 'VBG'),\n",
       " ('particular', 'JJ'),\n",
       " ('area', 'NN'),\n",
       " ('intensity', 'NN'),\n",
       " ('color', 'NN'),\n",
       " ('shows', 'VBZ'),\n",
       " ('confident', 'JJ'),\n",
       " ('prediction', 'NN'),\n",
       " ('library', 'NN'),\n",
       " ('using', 'VBG'),\n",
       " ('wrote', 'VBD'),\n",
       " ('tiny', 'JJ'),\n",
       " ('neural', 'JJ'),\n",
       " ('network', 'NN'),\n",
       " ('library', 'JJ'),\n",
       " ('meets', 'NNS'),\n",
       " ('demands', 'VBZ'),\n",
       " ('educational', 'JJ'),\n",
       " ('visualization', 'NN'),\n",
       " ('real', 'JJ'),\n",
       " ('world', 'NN'),\n",
       " ('applications', 'NNS'),\n",
       " ('consider', 'VBP'),\n",
       " ('tensorflow', 'JJ'),\n",
       " ('library', 'NN'),\n",
       " ('credits', 'NNS'),\n",
       " ('created', 'VBN'),\n",
       " ('daniel', 'JJ'),\n",
       " ('smilkov', 'JJ'),\n",
       " ('carter', 'NN'),\n",
       " ('continuation', 'NN'),\n",
       " ('many', 'JJ'),\n",
       " ('people', 'NNS'),\n",
       " ('previous', 'JJ'),\n",
       " ('work', 'NN'),\n",
       " ('notably', 'RB'),\n",
       " ('andrej', 'VBZ'),\n",
       " ('karpathy', 'JJ'),\n",
       " ('convnet', 'NN'),\n",
       " ('js', 'NN'),\n",
       " ('demo', 'NN'),\n",
       " ('chris', 'NN'),\n",
       " ('olah', 'NN'),\n",
       " ('articles', 'VBZ'),\n",
       " ('neural', 'JJ'),\n",
       " ('networks', 'NNS'),\n",
       " ('many', 'JJ'),\n",
       " ('thanks', 'NNS'),\n",
       " ('also', 'RB'),\n",
       " ('sculley', 'VBP'),\n",
       " ('help', 'NN'),\n",
       " ('original', 'JJ'),\n",
       " ('idea', 'NN'),\n",
       " ('fernanda', 'NN'),\n",
       " ('vi', 'NN'),\n",
       " ('gas', 'NN'),\n",
       " ('martin', 'NN'),\n",
       " ('wattenberg', 'NN'),\n",
       " ('rest', 'NN'),\n",
       " ('big', 'JJ'),\n",
       " ('picture', 'NN'),\n",
       " ('google', 'NN'),\n",
       " ('brain', 'NN'),\n",
       " ('teams', 'NNS'),\n",
       " ('feedback', 'VBP'),\n",
       " ('guidance', 'NN'),\n",
       " ('source', 'NN'),\n",
       " ('github', 'NN')]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tags = nltk.pos_tag(all_words)\n",
    "#word_tags = nltk.pos_tag(all_words)\n",
    "word_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CD',\n",
       " 'FW',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'JJR',\n",
       " 'NN',\n",
       " 'NNP',\n",
       " 'NNS',\n",
       " 'PRP',\n",
       " 'RB',\n",
       " 'RBR',\n",
       " 'RP',\n",
       " 'VB',\n",
       " 'VBD',\n",
       " 'VBG',\n",
       " 'VBN',\n",
       " 'VBP',\n",
       " 'VBZ',\n",
       " 'WDT'}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(set([word[1] for word in word_tags]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processor(word):\n",
    "    if word[1] in ['NN', 'FW', 'JJ', 'VB', 'VBP']:\n",
    "        result = word[0]\n",
    "        return result\n",
    "    elif word[1] in ['RB', 'RBR', 'RBS', 'RP', 'JJS', 'JJR','NNS','VBD','VBG','VBN', 'VBZ' ]:\n",
    "        result = snow_stem(word[0])\n",
    "        return result\n",
    "    elif word[1] in ['PRT','PRON', 'PRP','.','NUM','DET', 'CONJ', 'EX','CC', 'CD','IN','LS','UH','TO','NNP' 'WDT', 'WP','WRB','WP$']:\n",
    "        pass\n",
    "        return ''\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words = [text_processor(swords) for swords in word_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['copyright',\n",
       " 'tensorflow',\n",
       " 'hub',\n",
       " 'author',\n",
       " 'licens',\n",
       " 'apache',\n",
       " 'license',\n",
       " 'version',\n",
       " 'license',\n",
       " 'predict',\n",
       " 'shakespeare',\n",
       " 'cloud',\n",
       " 'tpus',\n",
       " 'keras',\n",
       " 'overview',\n",
       " 'example',\n",
       " 'use',\n",
       " 'tf',\n",
       " 'kera',\n",
       " 'build',\n",
       " 'language',\n",
       " 'model',\n",
       " 'train',\n",
       " 'cloud',\n",
       " 'tpu',\n",
       " 'language',\n",
       " 'model',\n",
       " 'predict',\n",
       " 'next',\n",
       " 'character',\n",
       " 'text',\n",
       " 'given',\n",
       " 'text',\n",
       " 'far',\n",
       " 'trained',\n",
       " 'model',\n",
       " 'generate',\n",
       " 'new',\n",
       " 'snippet',\n",
       " 'text',\n",
       " 'read',\n",
       " 'similar',\n",
       " 'style',\n",
       " 'text',\n",
       " 'training',\n",
       " 'data',\n",
       " 'model',\n",
       " 'train',\n",
       " 'epochs',\n",
       " 'complet',\n",
       " 'approxim',\n",
       " 'minut',\n",
       " 'notebook',\n",
       " 'host',\n",
       " 'github',\n",
       " 'view',\n",
       " 'original',\n",
       " 'repository',\n",
       " 'open',\n",
       " 'notebook',\n",
       " 'select',\n",
       " 'file',\n",
       " 'view',\n",
       " 'github',\n",
       " 'learn',\n",
       " 'object',\n",
       " 'colab',\n",
       " 'learn',\n",
       " 'build',\n",
       " 'layer',\n",
       " 'forward',\n",
       " 'lstm',\n",
       " 'model',\n",
       " 'convert',\n",
       " 'tf',\n",
       " 'kera',\n",
       " 'model',\n",
       " 'equivalent',\n",
       " 'tpu',\n",
       " 'version',\n",
       " 'use',\n",
       " 'standard',\n",
       " 'kera',\n",
       " 'method',\n",
       " 'train',\n",
       " 'fit',\n",
       " 'predict',\n",
       " 'evaluate',\n",
       " 'use',\n",
       " 'train',\n",
       " 'model',\n",
       " 'make',\n",
       " 'predict',\n",
       " 'generate',\n",
       " 'shakespeare',\n",
       " 'esque',\n",
       " 'play',\n",
       " 'instruct',\n",
       " 'train',\n",
       " 'tpu',\n",
       " 'main',\n",
       " 'menu',\n",
       " 'click',\n",
       " 'runtime',\n",
       " 'select',\n",
       " 'change',\n",
       " 'runtime',\n",
       " 'type',\n",
       " 'set',\n",
       " 'tpu',\n",
       " 'hardware',\n",
       " 'accelerator',\n",
       " 'click',\n",
       " 'runtime',\n",
       " 'select',\n",
       " 'runtime',\n",
       " 'run',\n",
       " 'also',\n",
       " 'run',\n",
       " 'cell',\n",
       " 'manual',\n",
       " 'shift',\n",
       " 'enter',\n",
       " 'tpus',\n",
       " 'locat',\n",
       " 'google',\n",
       " 'cloud',\n",
       " 'optimal',\n",
       " 'performance',\n",
       " 'read',\n",
       " 'data',\n",
       " 'direct',\n",
       " 'google',\n",
       " 'cloud',\n",
       " 'storage',\n",
       " 'gcs',\n",
       " 'data',\n",
       " 'model',\n",
       " 'training',\n",
       " 'example',\n",
       " 'train',\n",
       " 'model',\n",
       " 'combin',\n",
       " 'work',\n",
       " 'william',\n",
       " 'shakespeare',\n",
       " 'use',\n",
       " 'model',\n",
       " 'compose',\n",
       " 'play',\n",
       " 'style',\n",
       " 'great',\n",
       " 'bard',\n",
       " 'love',\n",
       " 'led',\n",
       " 'dumb',\n",
       " 'lack',\n",
       " 'berjoy',\n",
       " 'face',\n",
       " 'day',\n",
       " 'spirit',\n",
       " 'roar',\n",
       " 'shame',\n",
       " 'power',\n",
       " 'tied',\n",
       " 'remedi',\n",
       " 'lend',\n",
       " 'occasion',\n",
       " 'loud',\n",
       " 'lancaster',\n",
       " 'stabb',\n",
       " 'sword',\n",
       " 'ever',\n",
       " 'agripo',\n",
       " 'er',\n",
       " 'day',\n",
       " 'let',\n",
       " 'free',\n",
       " 'stop',\n",
       " 'word',\n",
       " 'profess',\n",
       " 'hour',\n",
       " 'stranger',\n",
       " 'life',\n",
       " 'sink',\n",
       " 'cri',\n",
       " 'aught',\n",
       " 'bed',\n",
       " 'seek',\n",
       " 'chaste',\n",
       " 'sens',\n",
       " 'prove',\n",
       " 'burn',\n",
       " 'perforc',\n",
       " 'seen',\n",
       " 'eye',\n",
       " 'fast',\n",
       " 'download',\n",
       " 'data',\n",
       " 'download',\n",
       " 'complete',\n",
       " 'work',\n",
       " 'shakespeare',\n",
       " 'single',\n",
       " 'text',\n",
       " 'file',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'use',\n",
       " 'snippet',\n",
       " 'file',\n",
       " 'train',\n",
       " 'data',\n",
       " 'model',\n",
       " 'target',\n",
       " 'snippet',\n",
       " 'offset',\n",
       " 'character',\n",
       " 'build',\n",
       " 'data',\n",
       " 'generator',\n",
       " 'build',\n",
       " 'model',\n",
       " 'model',\n",
       " 'defin',\n",
       " 'layer',\n",
       " 'forward',\n",
       " 'lstm',\n",
       " 'chang',\n",
       " 'tf',\n",
       " 'keras',\n",
       " 'standard',\n",
       " 'lstm',\n",
       " 'definition',\n",
       " 'define',\n",
       " 'input',\n",
       " 'shape',\n",
       " 'model',\n",
       " 'comply',\n",
       " 'compiler',\n",
       " 'static',\n",
       " 'shape',\n",
       " 'requirement',\n",
       " 'use',\n",
       " 'tf',\n",
       " 'train',\n",
       " 'optimizer',\n",
       " 'instead',\n",
       " 'standard',\n",
       " 'kera',\n",
       " 'optimizer',\n",
       " 'kera',\n",
       " 'optimizer',\n",
       " 'support',\n",
       " 'still',\n",
       " 'experimental',\n",
       " 'train',\n",
       " 'model',\n",
       " 'tf',\n",
       " 'contrib',\n",
       " 'tpu',\n",
       " 'keras',\n",
       " 'tpu',\n",
       " 'model',\n",
       " 'function',\n",
       " 'convert',\n",
       " 'tf',\n",
       " 'kera',\n",
       " 'model',\n",
       " 'equivalent',\n",
       " 'tpu',\n",
       " 'version',\n",
       " 'use',\n",
       " 'standard',\n",
       " 'kera',\n",
       " 'method',\n",
       " 'train',\n",
       " 'fit',\n",
       " 'predict',\n",
       " 'evaluate',\n",
       " 'make',\n",
       " 'predict',\n",
       " 'model',\n",
       " 'use',\n",
       " 'train',\n",
       " 'model',\n",
       " 'make',\n",
       " 'predict',\n",
       " 'generate',\n",
       " 'shakespeare',\n",
       " 'esque',\n",
       " 'play',\n",
       " 'start',\n",
       " 'model',\n",
       " 'seed',\n",
       " 'sentence',\n",
       " 'generate',\n",
       " 'charact',\n",
       " 'model',\n",
       " 'make',\n",
       " 'predict',\n",
       " 'initial',\n",
       " 'seed',\n",
       " 'learn',\n",
       " 'cloud',\n",
       " 'tpus',\n",
       " 'google',\n",
       " 'design',\n",
       " 'optim',\n",
       " 'specif',\n",
       " 'speed',\n",
       " 'scale',\n",
       " 'ml',\n",
       " 'workload',\n",
       " 'train',\n",
       " 'inference',\n",
       " 'enable',\n",
       " 'ml',\n",
       " 'engin',\n",
       " 'research',\n",
       " 'iterate',\n",
       " 'quick',\n",
       " 'explor',\n",
       " 'range',\n",
       " 'cloud',\n",
       " 'tpu',\n",
       " 'tutori',\n",
       " 'colabs',\n",
       " 'find',\n",
       " 'exampl',\n",
       " 'use',\n",
       " 'implement',\n",
       " 'ml',\n",
       " 'project',\n",
       " 'google',\n",
       " 'cloud',\n",
       " 'platform',\n",
       " 'addition',\n",
       " 'gpus',\n",
       " 'tpus',\n",
       " 'available',\n",
       " 'pre',\n",
       " 'configur',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'vms',\n",
       " 'find',\n",
       " 'automl',\n",
       " 'beta',\n",
       " 'training',\n",
       " 'custom',\n",
       " 'model',\n",
       " 'write',\n",
       " 'code',\n",
       " 'cloud',\n",
       " 'ml',\n",
       " 'engine',\n",
       " 'allow',\n",
       " 'run',\n",
       " 'parallel',\n",
       " 'train',\n",
       " 'hyperparamet',\n",
       " 'tune',\n",
       " 'custom',\n",
       " 'model',\n",
       " 'powerful',\n",
       " 'distribut',\n",
       " 'hardware',\n",
       " 'tinker',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'right',\n",
       " 'browser',\n",
       " 'worry',\n",
       " 'break',\n",
       " 'promise',\n",
       " 'replay',\n",
       " 'play',\n",
       " 'arrow',\n",
       " 'skip',\n",
       " 'next',\n",
       " 'epoch',\n",
       " 'learn',\n",
       " 'rate',\n",
       " 'activation',\n",
       " 'relu',\n",
       " 'tanh',\n",
       " 'sigmoid',\n",
       " 'linear',\n",
       " 'regularization',\n",
       " 'none',\n",
       " 'l',\n",
       " 'l',\n",
       " 'regularization',\n",
       " 'rate',\n",
       " 'problem',\n",
       " 'type',\n",
       " 'classification',\n",
       " 'regression',\n",
       " 'data',\n",
       " 'dataset',\n",
       " 'want',\n",
       " 'use',\n",
       " 'ratio',\n",
       " 'train',\n",
       " 'test',\n",
       " 'data',\n",
       " 'noise',\n",
       " 'batch',\n",
       " 'size',\n",
       " 'regenerate',\n",
       " 'featur',\n",
       " 'properti',\n",
       " 'want',\n",
       " 'feed',\n",
       " 'click',\n",
       " 'anywher',\n",
       " 'edit',\n",
       " 'weight',\n",
       " 'bias',\n",
       " 'output',\n",
       " 'neuron',\n",
       " 'hover',\n",
       " 'see',\n",
       " 'larger',\n",
       " 'output',\n",
       " 'mixed',\n",
       " 'vari',\n",
       " 'weight',\n",
       " 'shown',\n",
       " 'thickness',\n",
       " 'line',\n",
       " 'add',\n",
       " 'remove',\n",
       " 'output',\n",
       " 'test',\n",
       " 'loss',\n",
       " 'training',\n",
       " 'loss',\n",
       " 'color',\n",
       " 'show',\n",
       " 'data',\n",
       " 'neuron',\n",
       " 'weight',\n",
       " 'valu',\n",
       " 'show',\n",
       " 'test',\n",
       " 'data',\n",
       " 'discretize',\n",
       " 'output',\n",
       " 'keyboard',\n",
       " 'arrow',\n",
       " 'um',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'technique',\n",
       " 'building',\n",
       " 'computer',\n",
       " 'program',\n",
       " 'learn',\n",
       " 'data',\n",
       " 'base',\n",
       " 'loos',\n",
       " 'think',\n",
       " 'human',\n",
       " 'brain',\n",
       " 'work',\n",
       " 'first',\n",
       " 'collection',\n",
       " 'software',\n",
       " 'neuron',\n",
       " 'creat',\n",
       " 'connect',\n",
       " 'togeth',\n",
       " 'allow',\n",
       " 'send',\n",
       " 'messag',\n",
       " 'network',\n",
       " 'ask',\n",
       " 'solve',\n",
       " 'problem',\n",
       " 'attempt',\n",
       " 'time',\n",
       " 'strengthen',\n",
       " 'connect',\n",
       " 'lead',\n",
       " 'success',\n",
       " 'diminish',\n",
       " 'lead',\n",
       " 'failure',\n",
       " 'detail',\n",
       " 'introduction',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'michael',\n",
       " 'nielsen',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'deep',\n",
       " 'learn',\n",
       " 'good',\n",
       " 'place',\n",
       " 'start',\n",
       " 'technical',\n",
       " 'overview',\n",
       " 'try',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'ian',\n",
       " 'goodfellow',\n",
       " 'yoshua',\n",
       " 'bengio',\n",
       " 'aaron',\n",
       " 'courville',\n",
       " 'cool',\n",
       " 'repurpose',\n",
       " 'please',\n",
       " 'open',\n",
       " 'sourc',\n",
       " 'github',\n",
       " 'hope',\n",
       " 'make',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'littl',\n",
       " 'accessible',\n",
       " 'easier',\n",
       " 'learn',\n",
       " 'free',\n",
       " 'use',\n",
       " 'way',\n",
       " 'follow',\n",
       " 'apach',\n",
       " 'license',\n",
       " 'suggest',\n",
       " 'addit',\n",
       " 'chang',\n",
       " 'please',\n",
       " 'let',\n",
       " 'know',\n",
       " 'also',\n",
       " 'provid',\n",
       " 'control',\n",
       " 'enable',\n",
       " 'tailor',\n",
       " 'playground',\n",
       " 'specific',\n",
       " 'topic',\n",
       " 'lesson',\n",
       " 'choose',\n",
       " 'featur',\n",
       " 'visible',\n",
       " 'save',\n",
       " 'link',\n",
       " 'refresh',\n",
       " 'page',\n",
       " 'color',\n",
       " 'mean',\n",
       " 'orange',\n",
       " 'blue',\n",
       " 'use',\n",
       " 'visualization',\n",
       " 'slight',\n",
       " 'different',\n",
       " 'way',\n",
       " 'general',\n",
       " 'orange',\n",
       " 'show',\n",
       " 'negative',\n",
       " 'valu',\n",
       " 'blue',\n",
       " 'show',\n",
       " 'positive',\n",
       " 'valu',\n",
       " 'data',\n",
       " 'point',\n",
       " 'repres',\n",
       " 'small',\n",
       " 'circl',\n",
       " 'initi',\n",
       " 'color',\n",
       " 'orange',\n",
       " 'blue',\n",
       " 'correspond',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'hidden',\n",
       " 'layer',\n",
       " 'line',\n",
       " 'color',\n",
       " 'weight',\n",
       " 'connect',\n",
       " 'neuron',\n",
       " 'blue',\n",
       " 'show',\n",
       " 'positive',\n",
       " 'weight',\n",
       " 'mean',\n",
       " 'network',\n",
       " 'use',\n",
       " 'output',\n",
       " 'neuron',\n",
       " 'given',\n",
       " 'orang',\n",
       " 'line',\n",
       " 'show',\n",
       " 'network',\n",
       " 'assig',\n",
       " 'negative',\n",
       " 'weight',\n",
       " 'output',\n",
       " 'layer',\n",
       " 'dot',\n",
       " 'color',\n",
       " 'orange',\n",
       " 'blue',\n",
       " 'depend',\n",
       " 'original',\n",
       " 'valu',\n",
       " 'color',\n",
       " 'show',\n",
       " 'network',\n",
       " 'predict',\n",
       " 'particular',\n",
       " 'area',\n",
       " 'intensity',\n",
       " 'color',\n",
       " 'show',\n",
       " 'confident',\n",
       " 'prediction',\n",
       " 'library',\n",
       " 'use',\n",
       " 'wrote',\n",
       " 'tiny',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'library',\n",
       " 'meet',\n",
       " 'demand',\n",
       " 'educational',\n",
       " 'visualization',\n",
       " 'real',\n",
       " 'world',\n",
       " 'applic',\n",
       " 'consider',\n",
       " 'tensorflow',\n",
       " 'library',\n",
       " 'credit',\n",
       " 'creat',\n",
       " 'daniel',\n",
       " 'smilkov',\n",
       " 'carter',\n",
       " 'continuation',\n",
       " 'many',\n",
       " 'peopl',\n",
       " 'previous',\n",
       " 'work',\n",
       " 'notabl',\n",
       " 'andrej',\n",
       " 'karpathy',\n",
       " 'convnet',\n",
       " 'js',\n",
       " 'demo',\n",
       " 'chris',\n",
       " 'olah',\n",
       " 'articl',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'many',\n",
       " 'thank',\n",
       " 'also',\n",
       " 'sculley',\n",
       " 'help',\n",
       " 'original',\n",
       " 'idea',\n",
       " 'fernanda',\n",
       " 'vi',\n",
       " 'gas',\n",
       " 'martin',\n",
       " 'wattenberg',\n",
       " 'rest',\n",
       " 'big',\n",
       " 'picture',\n",
       " 'google',\n",
       " 'brain',\n",
       " 'team',\n",
       " 'feedback',\n",
       " 'guidance',\n",
       " 'source',\n",
       " 'github']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_words = []\n",
    "           \n",
    "for word in new_words:\n",
    "    if word != '':\n",
    "        k_words.append(word)\n",
    "\n",
    "k_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['copyright',\n",
       " 'tensorflow',\n",
       " 'hub',\n",
       " 'author',\n",
       " 'licens',\n",
       " 'apache',\n",
       " 'license',\n",
       " 'version',\n",
       " 'license',\n",
       " 'predict',\n",
       " 'shakespeare',\n",
       " 'cloud',\n",
       " 'tensor processing unit',\n",
       " 'keras',\n",
       " 'overview',\n",
       " 'example',\n",
       " 'use',\n",
       " 'tensorflow',\n",
       " 'keras',\n",
       " 'build',\n",
       " 'language',\n",
       " 'model',\n",
       " 'train',\n",
       " 'cloud',\n",
       " 'tensor processing unit',\n",
       " 'language',\n",
       " 'model',\n",
       " 'predict',\n",
       " 'next',\n",
       " 'character',\n",
       " 'text',\n",
       " 'given',\n",
       " 'text',\n",
       " 'far',\n",
       " 'trained',\n",
       " 'model',\n",
       " 'generate',\n",
       " 'new',\n",
       " 'snippet',\n",
       " 'text',\n",
       " 'read',\n",
       " 'similar',\n",
       " 'style',\n",
       " 'text',\n",
       " 'training',\n",
       " 'data',\n",
       " 'model',\n",
       " 'train',\n",
       " 'epochs',\n",
       " 'complet',\n",
       " 'approxim',\n",
       " 'minut',\n",
       " 'notebook',\n",
       " 'host',\n",
       " 'github',\n",
       " 'view',\n",
       " 'original',\n",
       " 'repository',\n",
       " 'open',\n",
       " 'notebook',\n",
       " 'select',\n",
       " 'file',\n",
       " 'view',\n",
       " 'github',\n",
       " 'learn',\n",
       " 'object',\n",
       " 'colab',\n",
       " 'learn',\n",
       " 'build',\n",
       " 'layer',\n",
       " 'forward',\n",
       " 'lstm',\n",
       " 'model',\n",
       " 'convert',\n",
       " 'tensorflow',\n",
       " 'keras',\n",
       " 'model',\n",
       " 'equivalent',\n",
       " 'tensor processing unit',\n",
       " 'version',\n",
       " 'use',\n",
       " 'standard',\n",
       " 'keras',\n",
       " 'method',\n",
       " 'train',\n",
       " 'fit',\n",
       " 'predict',\n",
       " 'evaluate',\n",
       " 'use',\n",
       " 'train',\n",
       " 'model',\n",
       " 'make',\n",
       " 'predict',\n",
       " 'generate',\n",
       " 'shakespeare',\n",
       " 'esque',\n",
       " 'play',\n",
       " 'instruct',\n",
       " 'train',\n",
       " 'tensor processing unit',\n",
       " 'main',\n",
       " 'menu',\n",
       " 'click',\n",
       " 'runtime',\n",
       " 'select',\n",
       " 'change',\n",
       " 'runtime',\n",
       " 'type',\n",
       " 'set',\n",
       " 'tensor processing unit',\n",
       " 'hardware',\n",
       " 'accelerator',\n",
       " 'click',\n",
       " 'runtime',\n",
       " 'select',\n",
       " 'runtime',\n",
       " 'run',\n",
       " 'also',\n",
       " 'run',\n",
       " 'cell',\n",
       " 'manual',\n",
       " 'shift',\n",
       " 'enter',\n",
       " 'tensor processing unit',\n",
       " 'locat',\n",
       " 'google',\n",
       " 'cloud',\n",
       " 'optimal',\n",
       " 'performance',\n",
       " 'read',\n",
       " 'data',\n",
       " 'direct',\n",
       " 'google',\n",
       " 'cloud',\n",
       " 'storage',\n",
       " 'gcs',\n",
       " 'data',\n",
       " 'model',\n",
       " 'training',\n",
       " 'example',\n",
       " 'train',\n",
       " 'model',\n",
       " 'combin',\n",
       " 'work',\n",
       " 'william',\n",
       " 'shakespeare',\n",
       " 'use',\n",
       " 'model',\n",
       " 'compose',\n",
       " 'play',\n",
       " 'style',\n",
       " 'great',\n",
       " 'bard',\n",
       " 'love',\n",
       " 'led',\n",
       " 'dumb',\n",
       " 'lack',\n",
       " 'berjoy',\n",
       " 'face',\n",
       " 'day',\n",
       " 'spirit',\n",
       " 'roar',\n",
       " 'shame',\n",
       " 'power',\n",
       " 'tied',\n",
       " 'remedi',\n",
       " 'lend',\n",
       " 'occasion',\n",
       " 'loud',\n",
       " 'lancaster',\n",
       " 'stabb',\n",
       " 'sword',\n",
       " 'ever',\n",
       " 'agripo',\n",
       " 'er',\n",
       " 'day',\n",
       " 'let',\n",
       " 'free',\n",
       " 'stop',\n",
       " 'word',\n",
       " 'profess',\n",
       " 'hour',\n",
       " 'stranger',\n",
       " 'life',\n",
       " 'sink',\n",
       " 'cri',\n",
       " 'aught',\n",
       " 'bed',\n",
       " 'seek',\n",
       " 'chaste',\n",
       " 'sens',\n",
       " 'prove',\n",
       " 'burn',\n",
       " 'perforc',\n",
       " 'seen',\n",
       " 'eye',\n",
       " 'fast',\n",
       " 'download',\n",
       " 'data',\n",
       " 'download',\n",
       " 'complete',\n",
       " 'work',\n",
       " 'shakespeare',\n",
       " 'single',\n",
       " 'text',\n",
       " 'file',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'use',\n",
       " 'snippet',\n",
       " 'file',\n",
       " 'train',\n",
       " 'data',\n",
       " 'model',\n",
       " 'target',\n",
       " 'snippet',\n",
       " 'offset',\n",
       " 'character',\n",
       " 'build',\n",
       " 'data',\n",
       " 'generator',\n",
       " 'build',\n",
       " 'model',\n",
       " 'model',\n",
       " 'defin',\n",
       " 'layer',\n",
       " 'forward',\n",
       " 'lstm',\n",
       " 'chang',\n",
       " 'tensorflow',\n",
       " 'keras',\n",
       " 'standard',\n",
       " 'lstm',\n",
       " 'definition',\n",
       " 'define',\n",
       " 'input',\n",
       " 'shape',\n",
       " 'model',\n",
       " 'comply',\n",
       " 'compiler',\n",
       " 'static',\n",
       " 'shape',\n",
       " 'requirement',\n",
       " 'use',\n",
       " 'tensorflow',\n",
       " 'train',\n",
       " 'optimizer',\n",
       " 'instead',\n",
       " 'standard',\n",
       " 'keras',\n",
       " 'optimizer',\n",
       " 'keras',\n",
       " 'optimizer',\n",
       " 'support',\n",
       " 'still',\n",
       " 'experimental',\n",
       " 'train',\n",
       " 'model',\n",
       " 'tensorflow',\n",
       " 'contrib',\n",
       " 'tensor processing unit',\n",
       " 'keras',\n",
       " 'tensor processing unit',\n",
       " 'model',\n",
       " 'function',\n",
       " 'convert',\n",
       " 'tensorflow',\n",
       " 'keras',\n",
       " 'model',\n",
       " 'equivalent',\n",
       " 'tensor processing unit',\n",
       " 'version',\n",
       " 'use',\n",
       " 'standard',\n",
       " 'keras',\n",
       " 'method',\n",
       " 'train',\n",
       " 'fit',\n",
       " 'predict',\n",
       " 'evaluate',\n",
       " 'make',\n",
       " 'predict',\n",
       " 'model',\n",
       " 'use',\n",
       " 'train',\n",
       " 'model',\n",
       " 'make',\n",
       " 'predict',\n",
       " 'generate',\n",
       " 'shakespeare',\n",
       " 'esque',\n",
       " 'play',\n",
       " 'start',\n",
       " 'model',\n",
       " 'seed',\n",
       " 'sentence',\n",
       " 'generate',\n",
       " 'charact',\n",
       " 'model',\n",
       " 'make',\n",
       " 'predict',\n",
       " 'initial',\n",
       " 'seed',\n",
       " 'learn',\n",
       " 'cloud',\n",
       " 'tensor processing unit',\n",
       " 'google',\n",
       " 'design',\n",
       " 'optim',\n",
       " 'specif',\n",
       " 'speed',\n",
       " 'scale',\n",
       " 'machine learning',\n",
       " 'workload',\n",
       " 'train',\n",
       " 'inference',\n",
       " 'enable',\n",
       " 'machine learning',\n",
       " 'engin',\n",
       " 'research',\n",
       " 'iterate',\n",
       " 'quick',\n",
       " 'explor',\n",
       " 'range',\n",
       " 'cloud',\n",
       " 'tensor processing unit',\n",
       " 'tutori',\n",
       " 'colabs',\n",
       " 'find',\n",
       " 'exampl',\n",
       " 'use',\n",
       " 'implement',\n",
       " 'machine learning',\n",
       " 'project',\n",
       " 'google',\n",
       " 'cloud',\n",
       " 'platform',\n",
       " 'addition',\n",
       " 'gpus',\n",
       " 'tensor processing unit',\n",
       " 'available',\n",
       " 'pre',\n",
       " 'configur',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'vms',\n",
       " 'find',\n",
       " 'automl',\n",
       " 'beta',\n",
       " 'training',\n",
       " 'custom',\n",
       " 'model',\n",
       " 'write',\n",
       " 'code',\n",
       " 'cloud',\n",
       " 'machine learning',\n",
       " 'engine',\n",
       " 'allow',\n",
       " 'run',\n",
       " 'parallel',\n",
       " 'train',\n",
       " 'hyperparamet',\n",
       " 'tune',\n",
       " 'custom',\n",
       " 'model',\n",
       " 'powerful',\n",
       " 'distribut',\n",
       " 'hardware',\n",
       " 'tinker',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'right',\n",
       " 'browser',\n",
       " 'worry',\n",
       " 'break',\n",
       " 'promise',\n",
       " 'replay',\n",
       " 'play',\n",
       " 'arrow',\n",
       " 'skip',\n",
       " 'next',\n",
       " 'epoch',\n",
       " 'learn',\n",
       " 'rate',\n",
       " 'activation',\n",
       " 'relu',\n",
       " 'tanh',\n",
       " 'sigmoid',\n",
       " 'linear',\n",
       " 'regularization',\n",
       " 'none',\n",
       " 'l',\n",
       " 'l',\n",
       " 'regularization',\n",
       " 'rate',\n",
       " 'problem',\n",
       " 'type',\n",
       " 'classification',\n",
       " 'regression',\n",
       " 'data',\n",
       " 'dataset',\n",
       " 'want',\n",
       " 'use',\n",
       " 'ratio',\n",
       " 'train',\n",
       " 'test',\n",
       " 'data',\n",
       " 'noise',\n",
       " 'batch',\n",
       " 'size',\n",
       " 'regenerate',\n",
       " 'featur',\n",
       " 'properti',\n",
       " 'want',\n",
       " 'feed',\n",
       " 'click',\n",
       " 'anywher',\n",
       " 'edit',\n",
       " 'weight',\n",
       " 'bias',\n",
       " 'output',\n",
       " 'neuron',\n",
       " 'hover',\n",
       " 'see',\n",
       " 'larger',\n",
       " 'output',\n",
       " 'mixed',\n",
       " 'vari',\n",
       " 'weight',\n",
       " 'shown',\n",
       " 'thickness',\n",
       " 'line',\n",
       " 'add',\n",
       " 'remove',\n",
       " 'output',\n",
       " 'test',\n",
       " 'loss',\n",
       " 'training',\n",
       " 'loss',\n",
       " 'color',\n",
       " 'show',\n",
       " 'data',\n",
       " 'neuron',\n",
       " 'weight',\n",
       " 'valu',\n",
       " 'show',\n",
       " 'test',\n",
       " 'data',\n",
       " 'discretize',\n",
       " 'output',\n",
       " 'keyboard',\n",
       " 'arrow',\n",
       " 'um',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'technique',\n",
       " 'building',\n",
       " 'computer',\n",
       " 'program',\n",
       " 'learn',\n",
       " 'data',\n",
       " 'base',\n",
       " 'loos',\n",
       " 'think',\n",
       " 'human',\n",
       " 'brain',\n",
       " 'work',\n",
       " 'first',\n",
       " 'collection',\n",
       " 'software',\n",
       " 'neuron',\n",
       " 'creat',\n",
       " 'connect',\n",
       " 'togeth',\n",
       " 'allow',\n",
       " 'send',\n",
       " 'messag',\n",
       " 'network',\n",
       " 'ask',\n",
       " 'solve',\n",
       " 'problem',\n",
       " 'attempt',\n",
       " 'time',\n",
       " 'strengthen',\n",
       " 'connect',\n",
       " 'lead',\n",
       " 'success',\n",
       " 'diminish',\n",
       " 'lead',\n",
       " 'failure',\n",
       " 'detail',\n",
       " 'introduction',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'michael',\n",
       " 'nielsen',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'deep',\n",
       " 'learn',\n",
       " 'good',\n",
       " 'place',\n",
       " 'start',\n",
       " 'technical',\n",
       " 'overview',\n",
       " 'try',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'ian',\n",
       " 'goodfellow',\n",
       " 'yoshua',\n",
       " 'bengio',\n",
       " 'aaron',\n",
       " 'courville',\n",
       " 'cool',\n",
       " 'repurpose',\n",
       " 'please',\n",
       " 'open',\n",
       " 'sourc',\n",
       " 'github',\n",
       " 'hope',\n",
       " 'make',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'littl',\n",
       " 'accessible',\n",
       " 'easier',\n",
       " 'learn',\n",
       " 'free',\n",
       " 'use',\n",
       " 'way',\n",
       " 'follow',\n",
       " 'apach',\n",
       " 'license',\n",
       " 'suggest',\n",
       " 'addit',\n",
       " 'chang',\n",
       " 'please',\n",
       " 'let',\n",
       " 'know',\n",
       " 'also',\n",
       " 'provid',\n",
       " 'control',\n",
       " 'enable',\n",
       " 'tailor',\n",
       " 'playground',\n",
       " 'specific',\n",
       " 'topic',\n",
       " 'lesson',\n",
       " 'choose',\n",
       " 'featur',\n",
       " 'visible',\n",
       " 'save',\n",
       " 'link',\n",
       " 'refresh',\n",
       " 'page',\n",
       " 'color',\n",
       " 'mean',\n",
       " 'orange',\n",
       " 'blue',\n",
       " 'use',\n",
       " 'visualization',\n",
       " 'slight',\n",
       " 'different',\n",
       " 'way',\n",
       " 'general',\n",
       " 'orange',\n",
       " 'show',\n",
       " 'negative',\n",
       " 'valu',\n",
       " 'blue',\n",
       " 'show',\n",
       " 'positive',\n",
       " 'valu',\n",
       " 'data',\n",
       " 'point',\n",
       " 'repres',\n",
       " 'small',\n",
       " 'circl',\n",
       " 'initi',\n",
       " 'color',\n",
       " 'orange',\n",
       " 'blue',\n",
       " 'correspond',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'hidden',\n",
       " 'layer',\n",
       " 'line',\n",
       " 'color',\n",
       " 'weight',\n",
       " 'connect',\n",
       " 'neuron',\n",
       " 'blue',\n",
       " 'show',\n",
       " 'positive',\n",
       " 'weight',\n",
       " 'mean',\n",
       " 'network',\n",
       " 'use',\n",
       " 'output',\n",
       " 'neuron',\n",
       " 'given',\n",
       " 'orang',\n",
       " 'line',\n",
       " 'show',\n",
       " 'network',\n",
       " 'assig',\n",
       " 'negative',\n",
       " 'weight',\n",
       " 'output',\n",
       " 'layer',\n",
       " 'dot',\n",
       " 'color',\n",
       " 'orange',\n",
       " 'blue',\n",
       " 'depend',\n",
       " 'original',\n",
       " 'valu',\n",
       " 'color',\n",
       " 'show',\n",
       " 'network',\n",
       " 'predict',\n",
       " 'particular',\n",
       " 'area',\n",
       " 'intensity',\n",
       " 'color',\n",
       " 'show',\n",
       " 'confident',\n",
       " 'prediction',\n",
       " 'library',\n",
       " 'use',\n",
       " 'wrote',\n",
       " 'tiny',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'library',\n",
       " 'meet',\n",
       " 'demand',\n",
       " 'educational',\n",
       " 'visualization',\n",
       " 'real',\n",
       " 'world',\n",
       " 'applic',\n",
       " 'consider',\n",
       " 'tensorflow',\n",
       " 'library',\n",
       " 'credit',\n",
       " 'creat',\n",
       " 'daniel',\n",
       " 'smilkov',\n",
       " 'carter',\n",
       " 'continuation',\n",
       " 'many',\n",
       " 'peopl',\n",
       " 'previous',\n",
       " 'work',\n",
       " 'notabl',\n",
       " 'andrej',\n",
       " 'karpathy',\n",
       " 'convnet',\n",
       " 'js',\n",
       " 'demo',\n",
       " 'chris',\n",
       " 'olah',\n",
       " 'articl',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'many',\n",
       " 'thank',\n",
       " 'also',\n",
       " 'sculley',\n",
       " 'help',\n",
       " 'original',\n",
       " 'idea',\n",
       " 'fernanda',\n",
       " 'vi',\n",
       " 'gas',\n",
       " 'martin',\n",
       " 'wattenberg',\n",
       " 'rest',\n",
       " 'big',\n",
       " 'picture',\n",
       " 'google',\n",
       " 'brain',\n",
       " 'team',\n",
       " 'feedback',\n",
       " 'guidance',\n",
       " 'source',\n",
       " 'github']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=[]\n",
    "for nword in k_words:\n",
    "    words.append(improve_abbrevations(nword))\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('model', 23),\n",
       " ('use', 14),\n",
       " ('train', 14),\n",
       " ('data', 12),\n",
       " ('network', 11),\n",
       " ('predict', 9),\n",
       " ('cloud', 8),\n",
       " ('tpu', 8),\n",
       " ('show', 8),\n",
       " ('kera', 7),\n",
       " ('learn', 7),\n",
       " ('neural', 7),\n",
       " ('color', 7),\n",
       " ('tf', 6),\n",
       " ('weight', 6)]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = Counter(k_words)\n",
    "top15 = list(cnt.most_common(15))\n",
    "top15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model',\n",
       " 'use',\n",
       " 'train',\n",
       " 'data',\n",
       " 'network',\n",
       " 'predict',\n",
       " 'cloud',\n",
       " 'tensor processing unit',\n",
       " 'show',\n",
       " 'keras',\n",
       " 'learn',\n",
       " 'neural',\n",
       " 'color',\n",
       " 'tensorflow',\n",
       " 'weight']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=[]\n",
    "for nword in top15:\n",
    "    words.append(improve_abbrevations(nword[0]))\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "wikipedia.set_lang(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def my_oxford_dictionary(word, app_id, app_key):\n",
    "    language = 'en'\n",
    "    word_id = word\n",
    "    url = 'https://od-api.oxforddictionaries.com:443/api/v1/entries/' + language + '/' + word_id.lower()\n",
    "    r = requests.get(url, headers={'app_id': app_id, 'app_key': app_key})\n",
    "\n",
    "    if r.status_code == 200:\n",
    "        data = r.json()\n",
    "        my_data = ((data[\"results\"][0][\"lexicalEntries\"][0])[\"entries\"][0][\"senses\"][0])[\"definitions\"][0]\n",
    "        return (my_data)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "\n",
    "app_id = '21b26fff'\n",
    "app_key = 'bc8ffaae3c2ccef118107e6cdd04e9b7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "top15_dict_ox ={}\n",
    "\n",
    "for every_word in words:\n",
    "    top15_dict_ox[every_word] = my_oxford_dictionary(every_word,app_id,app_key)\n",
    "    if top15_dict_ox[every_word] == '':\n",
    "        top15_dict_ox[every_word]  = wikipedia.summary(every_word, sentences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'a three-dimensional representation of a person or thing or of a proposed structure, typically on a smaller scale than the original',\n",
       " 'use': 'take, hold, or deploy (something) as a means of accomplishing or achieving something; employ',\n",
       " 'train': 'teach (a person or animal) a particular skill or type of behaviour through sustained practice and instruction',\n",
       " 'data': 'facts and statistics collected together for reference or analysis',\n",
       " 'network': 'an arrangement of intersecting horizontal and vertical lines',\n",
       " 'predict': 'say or estimate that (a specified thing) will happen in the future or will be a consequence of something',\n",
       " 'cloud': 'a visible mass of condensed watery vapour floating in the atmosphere, typically high above the general level of the ground',\n",
       " 'tensor processing unit': 'A tensor processing unit (TPU) is an AI accelerator application-specific integrated circuit (ASIC) developed by Google specifically for neural network machine learning.',\n",
       " 'show': 'be, allow, or cause to be visible',\n",
       " 'keras': 'Keras is an open source neural network library written in Python.',\n",
       " 'learn': 'gain or acquire knowledge of or skill in (something) by study, experience, or being taught',\n",
       " 'neural': 'relating to a nerve or the nervous system',\n",
       " 'color': 'Color (American English), or colour (Commonwealth English), is the characteristic of human visual perception described through color categories, with names such as red, orange, yellow, green, blue, or purple.',\n",
       " 'tensorflow': 'TensorFlow is an open-source software library for dataflow programming across a range of tasks.',\n",
       " 'weight': \"a body's relative mass or the quantity of matter contained by it, giving rise to a downward force; the heaviness of a person or thing\"}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top15_dict_ox"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
